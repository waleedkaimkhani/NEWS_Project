2024-12-31 16:28:26 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-12-31 16:28:26 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-12-31 16:28:26 [twisted] CRITICAL: Unhandled error in Deferred:
2024-12-31 16:28:26 [twisted] CRITICAL: Unhandled error in Deferred:
2024-12-31 16:28:26 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\twisted\internet\defer.py", line 2000, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\crawler.py", line 158, in crawl
    self.engine = self._create_engine()
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\crawler.py", line 172, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\core\engine.py", line 101, in __init__
    self.scraper = Scraper(crawler)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\core\scraper.py", line 109, in __init__
    self.itemproc: ItemPipelineManager = itemproc_cls.from_crawler(crawler)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\middleware.py", line 90, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\middleware.py", line 66, in from_settings
    mwcls = load_object(clspath)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\utils\misc.py", line 79, in load_object
    mod = import_module(module)
  File "C:\ProgramData\anaconda3\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1126, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1140, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'news_scraper'
2024-12-31 16:28:26 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\twisted\internet\defer.py", line 2000, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\crawler.py", line 158, in crawl
    self.engine = self._create_engine()
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\crawler.py", line 172, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\core\engine.py", line 101, in __init__
    self.scraper = Scraper(crawler)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\core\scraper.py", line 109, in __init__
    self.itemproc: ItemPipelineManager = itemproc_cls.from_crawler(crawler)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\middleware.py", line 90, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\middleware.py", line 66, in from_settings
    mwcls = load_object(clspath)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\utils\misc.py", line 79, in load_object
    mod = import_module(module)
  File "C:\ProgramData\anaconda3\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1126, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1140, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'news_scraper'
2024-12-31 16:31:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-12-31 16:31:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-12-31 16:31:13 [twisted] CRITICAL: Unhandled error in Deferred:
2024-12-31 16:31:13 [twisted] CRITICAL: Unhandled error in Deferred:
2024-12-31 16:31:13 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\twisted\internet\defer.py", line 2000, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\crawler.py", line 158, in crawl
    self.engine = self._create_engine()
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\crawler.py", line 172, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\core\engine.py", line 101, in __init__
    self.scraper = Scraper(crawler)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\core\scraper.py", line 109, in __init__
    self.itemproc: ItemPipelineManager = itemproc_cls.from_crawler(crawler)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\middleware.py", line 90, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\middleware.py", line 66, in from_settings
    mwcls = load_object(clspath)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\utils\misc.py", line 79, in load_object
    mod = import_module(module)
  File "C:\ProgramData\anaconda3\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1126, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1140, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'news_scraper'
2024-12-31 16:31:13 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\twisted\internet\defer.py", line 2000, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\crawler.py", line 158, in crawl
    self.engine = self._create_engine()
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\crawler.py", line 172, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\core\engine.py", line 101, in __init__
    self.scraper = Scraper(crawler)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\core\scraper.py", line 109, in __init__
    self.itemproc: ItemPipelineManager = itemproc_cls.from_crawler(crawler)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\middleware.py", line 90, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\middleware.py", line 66, in from_settings
    mwcls = load_object(clspath)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\utils\misc.py", line 79, in load_object
    mod = import_module(module)
  File "C:\ProgramData\anaconda3\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1126, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1140, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'news_scraper'
2024-12-31 16:32:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-12-31 16:32:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-12-31 16:32:44 [twisted] CRITICAL: Unhandled error in Deferred:
2024-12-31 16:32:44 [twisted] CRITICAL: Unhandled error in Deferred:
2024-12-31 16:32:44 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\twisted\internet\defer.py", line 2000, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\crawler.py", line 158, in crawl
    self.engine = self._create_engine()
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\crawler.py", line 172, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\core\engine.py", line 101, in __init__
    self.scraper = Scraper(crawler)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\core\scraper.py", line 109, in __init__
    self.itemproc: ItemPipelineManager = itemproc_cls.from_crawler(crawler)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\middleware.py", line 90, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\middleware.py", line 66, in from_settings
    mwcls = load_object(clspath)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\utils\misc.py", line 79, in load_object
    mod = import_module(module)
  File "C:\ProgramData\anaconda3\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1126, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1140, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'news_scraper'
2024-12-31 16:32:44 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\twisted\internet\defer.py", line 2000, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\crawler.py", line 158, in crawl
    self.engine = self._create_engine()
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\crawler.py", line 172, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\core\engine.py", line 101, in __init__
    self.scraper = Scraper(crawler)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\core\scraper.py", line 109, in __init__
    self.itemproc: ItemPipelineManager = itemproc_cls.from_crawler(crawler)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\middleware.py", line 90, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\middleware.py", line 66, in from_settings
    mwcls = load_object(clspath)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\utils\misc.py", line 79, in load_object
    mod = import_module(module)
  File "C:\ProgramData\anaconda3\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1126, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1140, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'news_scraper'
2024-12-31 18:10:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-12-31 18:10:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-12-31 18:10:01 [twisted] CRITICAL: Unhandled error in Deferred:
2024-12-31 18:10:01 [twisted] CRITICAL: Unhandled error in Deferred:
2024-12-31 18:10:01 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\twisted\internet\defer.py", line 2000, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\crawler.py", line 158, in crawl
    self.engine = self._create_engine()
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\crawler.py", line 172, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\core\engine.py", line 101, in __init__
    self.scraper = Scraper(crawler)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\core\scraper.py", line 109, in __init__
    self.itemproc: ItemPipelineManager = itemproc_cls.from_crawler(crawler)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\middleware.py", line 90, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\middleware.py", line 66, in from_settings
    mwcls = load_object(clspath)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\utils\misc.py", line 79, in load_object
    mod = import_module(module)
  File "C:\ProgramData\anaconda3\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1126, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1140, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'news_scraper'
2024-12-31 18:10:01 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\twisted\internet\defer.py", line 2000, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\crawler.py", line 158, in crawl
    self.engine = self._create_engine()
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\crawler.py", line 172, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\core\engine.py", line 101, in __init__
    self.scraper = Scraper(crawler)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\core\scraper.py", line 109, in __init__
    self.itemproc: ItemPipelineManager = itemproc_cls.from_crawler(crawler)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\middleware.py", line 90, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\middleware.py", line 66, in from_settings
    mwcls = load_object(clspath)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\utils\misc.py", line 79, in load_object
    mod = import_module(module)
  File "C:\ProgramData\anaconda3\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1126, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1140, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'news_scraper'
2024-12-31 18:13:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-12-31 18:13:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-12-31 18:13:55 [twisted] CRITICAL: Unhandled error in Deferred:
2024-12-31 18:13:55 [twisted] CRITICAL: Unhandled error in Deferred:
2024-12-31 18:13:55 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\twisted\internet\defer.py", line 2000, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\crawler.py", line 158, in crawl
    self.engine = self._create_engine()
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\crawler.py", line 172, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\core\engine.py", line 101, in __init__
    self.scraper = Scraper(crawler)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\core\scraper.py", line 109, in __init__
    self.itemproc: ItemPipelineManager = itemproc_cls.from_crawler(crawler)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\middleware.py", line 90, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\middleware.py", line 66, in from_settings
    mwcls = load_object(clspath)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\utils\misc.py", line 79, in load_object
    mod = import_module(module)
  File "C:\ProgramData\anaconda3\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1126, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1140, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'news_scraper'
2024-12-31 18:13:55 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\twisted\internet\defer.py", line 2000, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\crawler.py", line 158, in crawl
    self.engine = self._create_engine()
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\crawler.py", line 172, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\core\engine.py", line 101, in __init__
    self.scraper = Scraper(crawler)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\core\scraper.py", line 109, in __init__
    self.itemproc: ItemPipelineManager = itemproc_cls.from_crawler(crawler)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\middleware.py", line 90, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\middleware.py", line 66, in from_settings
    mwcls = load_object(clspath)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\utils\misc.py", line 79, in load_object
    mod = import_module(module)
  File "C:\ProgramData\anaconda3\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1126, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1140, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'news_scraper'
2024-12-31 18:13:59 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-12-31 18:13:59 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-12-31 18:13:59 [twisted] CRITICAL: Unhandled error in Deferred:
2024-12-31 18:13:59 [twisted] CRITICAL: Unhandled error in Deferred:
2024-12-31 18:13:59 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\twisted\internet\defer.py", line 2000, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\crawler.py", line 158, in crawl
    self.engine = self._create_engine()
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\crawler.py", line 172, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\core\engine.py", line 101, in __init__
    self.scraper = Scraper(crawler)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\core\scraper.py", line 109, in __init__
    self.itemproc: ItemPipelineManager = itemproc_cls.from_crawler(crawler)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\middleware.py", line 90, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\middleware.py", line 66, in from_settings
    mwcls = load_object(clspath)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\utils\misc.py", line 79, in load_object
    mod = import_module(module)
  File "C:\ProgramData\anaconda3\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1126, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1140, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'news_scraper'
2024-12-31 18:13:59 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\twisted\internet\defer.py", line 2000, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\crawler.py", line 158, in crawl
    self.engine = self._create_engine()
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\crawler.py", line 172, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\core\engine.py", line 101, in __init__
    self.scraper = Scraper(crawler)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\core\scraper.py", line 109, in __init__
    self.itemproc: ItemPipelineManager = itemproc_cls.from_crawler(crawler)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\middleware.py", line 90, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\middleware.py", line 66, in from_settings
    mwcls = load_object(clspath)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\utils\misc.py", line 79, in load_object
    mod = import_module(module)
  File "C:\ProgramData\anaconda3\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1126, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1140, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'news_scraper'
2024-12-31 18:14:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-12-31 18:14:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-12-31 18:14:11 [twisted] CRITICAL: Unhandled error in Deferred:
2024-12-31 18:14:11 [twisted] CRITICAL: Unhandled error in Deferred:
2024-12-31 18:14:11 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\twisted\internet\defer.py", line 2000, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\crawler.py", line 158, in crawl
    self.engine = self._create_engine()
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\crawler.py", line 172, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\core\engine.py", line 101, in __init__
    self.scraper = Scraper(crawler)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\core\scraper.py", line 109, in __init__
    self.itemproc: ItemPipelineManager = itemproc_cls.from_crawler(crawler)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\middleware.py", line 90, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\middleware.py", line 66, in from_settings
    mwcls = load_object(clspath)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\utils\misc.py", line 79, in load_object
    mod = import_module(module)
  File "C:\ProgramData\anaconda3\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1126, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1140, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'news_scraper'
2024-12-31 18:14:11 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\twisted\internet\defer.py", line 2000, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\crawler.py", line 158, in crawl
    self.engine = self._create_engine()
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\crawler.py", line 172, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\core\engine.py", line 101, in __init__
    self.scraper = Scraper(crawler)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\core\scraper.py", line 109, in __init__
    self.itemproc: ItemPipelineManager = itemproc_cls.from_crawler(crawler)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\middleware.py", line 90, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\middleware.py", line 66, in from_settings
    mwcls = load_object(clspath)
  File "C:\Users\WALEED\AppData\Roaming\Python\Python311\site-packages\scrapy\utils\misc.py", line 79, in load_object
    mod = import_module(module)
  File "C:\ProgramData\anaconda3\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1126, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1140, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'news_scraper'
2024-12-31 18:16:39 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-12-31 18:16:39 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-12-31 18:16:39 [scrapy.middleware] INFO: Enabled item pipelines:
['news_scrapper.pipelines.NewsValidationPipeline',
 'news_scrapper.pipelines.DuplicateCheckPipeline',
 'news_scrapper.pipelines.SQLitePipeline',
 'news_scrapper.pipelines.JsonExportPipeline']
2024-12-31 18:16:39 [scrapy.core.engine] INFO: Spider opened
2024-12-31 18:16:39 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-12-31 18:16:39 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
